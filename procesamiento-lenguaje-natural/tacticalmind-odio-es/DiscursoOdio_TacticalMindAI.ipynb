{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Análisis de Discurso de Odio en Español\n",
    "Este cuaderno presenta un pipeline profesional de NLP para caracterizar textos con posibles patrones de discurso de odio utilizando spaCy y análisis estadístico.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '02Dataset_anonimizado.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 18\u001b[39m\n\u001b[32m     15\u001b[39m BAD_BYTES = {\u001b[32m0xBF\u001b[39m, \u001b[32m0xA1\u001b[39m, \u001b[32m0xB3\u001b[39m}  \n\u001b[32m     17\u001b[39m \u001b[38;5;66;03m# Eliminamos esos bytes a nivel binario\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m18\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[43minput_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f_in, tmp_path.open(\u001b[33m\"\u001b[39m\u001b[33mwb\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f_out:\n\u001b[32m     19\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m raw_line \u001b[38;5;129;01min\u001b[39;00m f_in:\n\u001b[32m     20\u001b[39m         cleaned = \u001b[38;5;28mbytes\u001b[39m(b \u001b[38;5;28;01mfor\u001b[39;00m b \u001b[38;5;129;01min\u001b[39;00m raw_line \u001b[38;5;28;01mif\u001b[39;00m b \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m BAD_BYTES)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~\\.conda\\envs\\unir-pln\\Lib\\pathlib.py:1013\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1011\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1012\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1013\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mio\u001b[49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffering\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnewline\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '02Dataset_anonimizado.csv'"
     ]
    }
   ],
   "source": [
    "# Limpieza inicial del dataset (encoding y caracteres raros) \n",
    "# Basado en el script compartido por el profesor en el foro\n",
    "# Objetivo: dejar el corpus en UTF-8 legible\n",
    "\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "\n",
    "# Rutas de entrada/salida\n",
    "input_path = Path(\"Dataset.csv\")         # fichero original \n",
    "tmp_path = Path(\"Dataset_tmp_sin_bytes_raros.csv\")   # fichero intermedio\n",
    "output_path = Path(\"Dataset_comentarios_limpios_utf8.csv\")      # fichero final limpio\n",
    "\n",
    "# Algunos bytes problemáticos detectados en el archivo original\n",
    "# (provocan símbolos raros si no se eliminan)\n",
    "BAD_BYTES = {0xBF, 0xA1, 0xB3}  \n",
    "\n",
    "# Eliminamos esos bytes a nivel binario\n",
    "with input_path.open(\"rb\") as f_in, tmp_path.open(\"wb\") as f_out:\n",
    "    for raw_line in f_in:\n",
    "        cleaned = bytes(b for b in raw_line if b not in BAD_BYTES)\n",
    "        f_out.write(cleaned)\n",
    "\n",
    "# Leemos el CSV  con codificación latin1\n",
    "df = pd.read_csv(tmp_path, sep = \";\", encoding = \"latin1\", low_memory = False)\n",
    "\n",
    "def arreglar_mojibake(s):\n",
    "    #Función de limpieza de texto: Aplica una tabla de reemplazos manual para casos que no se corrigen bien.\n",
    "    if not isinstance(s, str):\n",
    "        return s\n",
    "    \n",
    "    # Primero intento el patrón latin1 a utf-8\n",
    "    try:\n",
    "        reparado = s.encode(\"latin1\").decode(\"utf-8\")\n",
    "    except UnicodeError:\n",
    "        reparado = s\n",
    "    \n",
    "    # Después aplico los reemplazos manuales (Ã± ñ Â¿ ¿)\n",
    "    for malo, bueno in REEMPLAZOS.items():\n",
    "        reparado = reparado.replace(malo, bueno)\n",
    "    \n",
    "    return reparado\n",
    "\n",
    "# Aplico la limpieza a todas las columnas de texto (tipo object)\n",
    "text_cols = df.select_dtypes(include = \"object\").columns\n",
    "for col in text_cols:\n",
    "    df[col] = df[col].apply(arreglar_mojibake)\n",
    "\n",
    "# Elimino columnas sin nombre que vienen vacías\n",
    "df = df.loc[:, ~df.columns.str.startswith(\"Unnamed\")]\n",
    "\n",
    "# Guardamos el utf-8 limpio\n",
    "df.to_csv(output_path, sep = \";\", index=False, encoding = \"utf-8\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import spacy\n",
    "import pandas as pd\n",
    "from spacy import displacy\n",
    "import csv\n",
    "import es_core_news_md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = es_core_news_md.load()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 9)\n",
      "Index(['MEDIO', 'SOPORTE', 'URL', 'TIPO DE MENSAJE', 'CONTENIDO A ANALIZAR',\n",
      "       'INTENSIDAD', 'TIPO DE ODIO', 'TONO HUMORISTICO', 'MODIFICADOR'],\n",
      "      dtype='object')\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>MEDIO</th>\n",
       "      <th>SOPORTE</th>\n",
       "      <th>URL</th>\n",
       "      <th>TIPO DE MENSAJE</th>\n",
       "      <th>CONTENIDO A ANALIZAR</th>\n",
       "      <th>INTENSIDAD</th>\n",
       "      <th>TIPO DE ODIO</th>\n",
       "      <th>TONO HUMORISTICO</th>\n",
       "      <th>MODIFICADOR</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>EL PAÍS</td>\n",
       "      <td>WEB</td>\n",
       "      <td>URL_a4d7efc0</td>\n",
       "      <td>COMENTARIO</td>\n",
       "      <td>el barça nunca acaeza ante un segundo b ni ant...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Otros</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>EL PAÍS</td>\n",
       "      <td>WEB</td>\n",
       "      <td>URL_a4d7efc0</td>\n",
       "      <td>COMENTARIO</td>\n",
       "      <td>el real madrid ha puesto punto y final a su an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>EL PAÍS</td>\n",
       "      <td>WEB</td>\n",
       "      <td>URL_54312d9e</td>\n",
       "      <td>COMENTARIO</td>\n",
       "      <td>cristina cifuentes podrí­a haber sido la presi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ideológico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>EL PAÍS</td>\n",
       "      <td>WEB</td>\n",
       "      <td>URL_54312d9e</td>\n",
       "      <td>COMENTARIO</td>\n",
       "      <td>habrí­a que reabrir el caso. el supremo se ded...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ideológico</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>EL PAÍS</td>\n",
       "      <td>WEB</td>\n",
       "      <td>URL_54312d9e</td>\n",
       "      <td>COMENTARIO</td>\n",
       "      <td>me parece un poco exagerado pedir más de tres ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Ideológico</td>\n",
       "      <td>Si</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      MEDIO SOPORTE           URL TIPO DE MENSAJE  \\\n",
       "0  EL PAÍS      WEB  URL_a4d7efc0      COMENTARIO   \n",
       "1  EL PAÍS      WEB  URL_a4d7efc0      COMENTARIO   \n",
       "2  EL PAÍS      WEB  URL_54312d9e      COMENTARIO   \n",
       "3  EL PAÍS      WEB  URL_54312d9e      COMENTARIO   \n",
       "4  EL PAÍS      WEB  URL_54312d9e      COMENTARIO   \n",
       "\n",
       "                                CONTENIDO A ANALIZAR  INTENSIDAD TIPO DE ODIO  \\\n",
       "0  el barça nunca acaeza ante un segundo b ni ant...         3.0        Otros   \n",
       "1  el real madrid ha puesto punto y final a su an...         0.0          NaN   \n",
       "2  cristina cifuentes podrí­a haber sido la presi...         3.0   Ideológico   \n",
       "3  habrí­a que reabrir el caso. el supremo se ded...         3.0   Ideológico   \n",
       "4  me parece un poco exagerado pedir más de tres ...         3.0   Ideológico   \n",
       "\n",
       "  TONO HUMORISTICO MODIFICADOR  \n",
       "0              NaN         NaN  \n",
       "1              NaN         NaN  \n",
       "2              NaN         NaN  \n",
       "3              NaN         NaN  \n",
       "4               Si         NaN  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Nombre del fichero limpio\n",
    "filename = \"./Dataset_comentarios_limpios_utf8.csv\"\n",
    "lines_number = 10000  # máximo de filas a leer (limitamos a 10000 para no saturar)\n",
    "\n",
    "# Carga del CSV limpio en un DataFrame de pandas\n",
    "data = pd.read_csv(\n",
    "    filename,\n",
    "    sep = \";\",         # separador del dataset\n",
    "    encoding = \"utf-8\",  # todo el contenido en UTF-8\n",
    "    nrows = lines_number\n",
    ")\n",
    "\n",
    "# Eliminamos columnas totalmente vacías\n",
    "data = data.dropna(axis = 1, how = \"all\")\n",
    "\n",
    "print(data.shape)\n",
    "print(data.columns)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número de filas en data: 10000\n",
      "el\n",
      "barça\n",
      "nunca\n",
      "acaeza\n",
      "ante\n",
      "un\n",
      "segundo\n",
      "b\n",
      "ni\n",
      "ante\n",
      "un\n",
      "tercera\n",
      ",\n",
      "ya\n",
      "estan\n",
      "los\n",
      "arbitros\n",
      "para\n",
      "impedirlo\n",
      "....\n",
      "lo\n",
      "de\n",
      "messi\n",
      "es\n",
      "una\n",
      "autentica\n",
      "vergí¼enza\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CONTENIDO A ANALIZAR</th>\n",
       "      <th>INTENSIDAD</th>\n",
       "      <th>ES_ODIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>el barça nunca acaeza ante un segundo b ni ant...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>el real madrid ha puesto punto y final a su an...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cristina cifuentes podrí­a haber sido la presi...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>habrí­a que reabrir el caso. el supremo se ded...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>me parece un poco exagerado pedir más de tres ...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                CONTENIDO A ANALIZAR  INTENSIDAD  ES_ODIO\n",
       "0  el barça nunca acaeza ante un segundo b ni ant...         3.0     True\n",
       "1  el real madrid ha puesto punto y final a su an...         0.0    False\n",
       "2  cristina cifuentes podrí­a haber sido la presi...         3.0     True\n",
       "3  habrí­a que reabrir el caso. el supremo se ded...         3.0     True\n",
       "4  me parece un poco exagerado pedir más de tres ...         3.0     True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Convierto la columna de texto a lista de strings\n",
    "# Proceso todos los comentarios con spaCy (usando nlp.pipe por eficiencia)\n",
    "# Creo columnas auxiliares en el DataFrame: DOC, INTENSIDAD, ES_ODIO\n",
    "# Añado también N_PALABRAS, N_ORACIONES y TIENE_NER\n",
    "\n",
    "# Convierto la columna de texto a lista de strings, evitando NaN\n",
    "textos = data[\"CONTENIDO A ANALIZAR\"].fillna(\"\").astype(str).tolist()\n",
    "\n",
    "doc_list = []\n",
    "value_list = []\n",
    "\n",
    "# Procesamiento en batch con nlp.pipe para mejorar el rendimiento\n",
    "for tmp_doc, tmp_value in zip(nlp.pipe(textos, batch_size = 100), data[\"INTENSIDAD\"]):\n",
    "    doc_list.append(tmp_doc)    # objeto spaCy Doc\n",
    "    value_list.append(tmp_value)\n",
    "\n",
    "# Guardo las listas en variables por si las necesito directamente\n",
    "doc = doc_list          # lista de documentos spaCy\n",
    "value = value_list      # intensidades asociadas\n",
    "\n",
    "# Añado columnas al DataFrame\n",
    "data[\"DOC\"] = doc\n",
    "data[\"INTENSIDAD\"] = pd.to_numeric(data[\"INTENSIDAD\"], errors = \"coerce\")\n",
    "\n",
    "# ES_ODIO será True si la intensidad es mayor que 0\n",
    "data[\"ES_ODIO\"] = data[\"INTENSIDAD\"] > 0\n",
    "\n",
    "print(\"Número de filas en data:\", len(data))\n",
    "for token in data[\"DOC\"].iloc[0]:\n",
    "    print(token)\n",
    "\n",
    "data[[\"CONTENIDO A ANALIZAR\", \"INTENSIDAD\", \"ES_ODIO\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>N_PALABRAS</th>\n",
       "      <th>N_ORACIONES</th>\n",
       "      <th>TIENE_NER</th>\n",
       "      <th>ES_ODIO</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>195</td>\n",
       "      <td>9</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>127</td>\n",
       "      <td>7</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>147</td>\n",
       "      <td>6</td>\n",
       "      <td>True</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   N_PALABRAS  N_ORACIONES  TIENE_NER  ES_ODIO\n",
       "0          25            2       True     True\n",
       "1         195            9       True    False\n",
       "2         127            7       True     True\n",
       "3          19            3      False     True\n",
       "4         147            6       True     True"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# En esta celda defino funciones para extraer características de cada comentario a partir del objeto spaCy Doc\n",
    "\n",
    "def contar_palabras(doc_spacy):\n",
    "    #Devuelve el número de palabras de contenido en un Doc, excluyendo puntuación y espacios\n",
    "    return sum(1 for t in doc_spacy if not t.is_punct and not t.is_space)\n",
    "\n",
    "def contar_oraciones(doc_spacy):\n",
    "    #Devuelve el número de oraciones en un Doc usando los segmentos de spaCy\n",
    "    return len(list(doc_spacy.sents))\n",
    "\n",
    "def tiene_ner(doc_spacy):\n",
    "    #Indica si el Doc tiene al menos una entidad nombrada\n",
    "    return len(doc_spacy.ents) > 0\n",
    "\n",
    "# Aplico las funciones a cada documento y creo columnas derivadas\n",
    "data[\"N_PALABRAS\"] = data[\"DOC\"].apply(contar_palabras)\n",
    "data[\"N_ORACIONES\"] = data[\"DOC\"].apply(contar_oraciones)\n",
    "data[\"TIENE_NER\"] = data[\"DOC\"].apply(tiene_ner)\n",
    "\n",
    "# Vista de las nuevas columnas\n",
    "data[[\"N_PALABRAS\", \"N_ORACIONES\", \"TIENE_NER\", \"ES_ODIO\"]].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "El corpus contiene 10000 registros\n"
     ]
    }
   ],
   "source": [
    "# Cada fila del DataFrame 'data' corresponde a un comentario. Por tanto, el número de registros es el número de filas\n",
    "num_registros = len(data)\n",
    "print(f\"El corpus contiene {num_registros} registros\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total de palabras (tokens) en el corpus: 216448\n"
     ]
    }
   ],
   "source": [
    "# Uso la columna 'N_PALABRAS', que ya contiene el número de palabras de contenido por comentario y sumo todos los valores\n",
    "total_palabras = int(data[\"N_PALABRAS\"].sum())\n",
    "print(f\"Total de palabras (tokens) en el corpus: {total_palabras}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Número promedio de palabras por comentario: 21.64\n"
     ]
    }
   ],
   "source": [
    "# A partir de 'N_PALABRAS', calculo la media con la función mean() para tener una idea de la longitud típica de los comentarios\n",
    "promedio_palabras = data[\"N_PALABRAS\"].mean()\n",
    "print(f\"Número promedio de palabras por comentario: {promedio_palabras:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentarios con ODIO: 748\n",
      "Promedio de palabras (ODIO): 22.89\n",
      "\n",
      "Comentarios SIN ODIO: 9252\n",
      "Promedio de palabras (NO ODIO): 21.54\n"
     ]
    }
   ],
   "source": [
    "# Palabras por grupo (ODIO vs NO ODIO)\n",
    "# Número de comentarios por grupo\n",
    "count_por_grupo = data[\"ES_ODIO\"].value_counts()\n",
    "\n",
    "# Media de palabras por grupo con la columna N_PALABRAS\n",
    "medias_palabras = data.groupby(\"ES_ODIO\")[\"N_PALABRAS\"].mean()\n",
    "\n",
    "print(f\"Comentarios con ODIO: {count_por_grupo[True]}\")\n",
    "print(f\"Promedio de palabras (ODIO): {medias_palabras[True]:.2f}\")\n",
    "print(f\"\\nComentarios SIN ODIO: {count_por_grupo[False]}\")\n",
    "print(f\"Promedio de palabras (NO ODIO): {medias_palabras[False]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentarios con ODIO: 748\n",
      "Promedio de oraciones (ODIO): 1.76\n",
      "\n",
      "Comentarios SIN ODIO: 9252\n",
      "Promedio de oraciones (NO ODIO): 1.78\n"
     ]
    }
   ],
   "source": [
    "# Promedio de oraciones en dos grupos: con odio y sin odio\n",
    "# Reutilizo 'count_por_grupo' de la celda anterior y calculo la media de oraciones por grupo usando 'N_ORACIONES'\n",
    "medias_oraciones = data.groupby(\"ES_ODIO\")[\"N_ORACIONES\"].mean()\n",
    "\n",
    "print(f\"Comentarios con ODIO: {count_por_grupo[True]}\")\n",
    "print(f\"Promedio de oraciones (ODIO): {medias_oraciones[True]:.2f}\")\n",
    "print(f\"\\nComentarios SIN ODIO: {count_por_grupo[False]}\")\n",
    "print(f\"Promedio de oraciones (NO ODIO): {medias_oraciones[False]:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Comentarios con ODIO: 748\n",
      "Con entidades NER: 286 (38.24%)\n",
      "\n",
      "Comentarios SIN ODIO: 9252\n",
      "Con entidades NER: 3119 (33.71%)\n"
     ]
    }
   ],
   "source": [
    "# Porcentaje de comentarios que contienen entidades NER\n",
    "# 'sum' indica cuántos tienen entidades y 'count' indica el total de comentarios en cada grupo\n",
    "tabla_ner = data.groupby(\"ES_ODIO\")[\"TIENE_NER\"].agg([\"sum\", \"count\"])\n",
    "\n",
    "comentarios_con_ner_odio = tabla_ner.loc[True, \"sum\"]\n",
    "total_odio = tabla_ner.loc[True, \"count\"]\n",
    "\n",
    "comentarios_con_ner_no_odio = tabla_ner.loc[False, \"sum\"]\n",
    "total_no_odio = tabla_ner.loc[False, \"count\"]\n",
    "\n",
    "porcentaje_ner_odio = comentarios_con_ner_odio / total_odio * 100\n",
    "porcentaje_ner_no_odio = comentarios_con_ner_no_odio / total_no_odio * 100\n",
    "\n",
    "print(f\"Comentarios con ODIO: {total_odio}\")\n",
    "print(f\"Con entidades NER: {comentarios_con_ner_odio} ({porcentaje_ner_odio:.2f}%)\")\n",
    "print(f\"\\nComentarios SIN ODIO: {total_no_odio}\")\n",
    "print(f\"Con entidades NER: {comentarios_con_ner_no_odio} ({porcentaje_ner_no_odio:.2f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODIO - Densidad de puntuación expresiva: 2.59%\n",
      "NO ODIO - Densidad de puntuación expresiva: 2.58%\n"
     ]
    }
   ],
   "source": [
    "# Densidad de signos de puntuación expresivos (!, ?, ...)\n",
    "import re\n",
    "\n",
    "puntuacion_odio = 0\n",
    "puntuacion_no_odio = 0\n",
    "total_palabras_odio = 0\n",
    "total_palabras_no_odio = 0\n",
    "\n",
    "# Recorro todos los comentarios y cuento signos del tipo: !, ?, !!, ??, ..., etc.\n",
    "for i in range(len(data)):\n",
    "    texto = data[\"CONTENIDO A ANALIZAR\"].iloc[i]\n",
    "    if isinstance(texto, str):\n",
    "        # Capturo secuencias de !, ?, o varios puntos\n",
    "        signos_expresivos = len(re.findall(r'[!?]+|\\.{2,}', texto))\n",
    "        num_palabras = data[\"N_PALABRAS\"].iloc[i]\n",
    "\n",
    "        if data[\"ES_ODIO\"].iloc[i]:\n",
    "            puntuacion_odio += signos_expresivos\n",
    "            total_palabras_odio += num_palabras\n",
    "        else:\n",
    "            puntuacion_no_odio += signos_expresivos\n",
    "            total_palabras_no_odio += num_palabras\n",
    "\n",
    "# Normalizo por número total de palabras del grupo y lo convierto a porcentaje\n",
    "densidad_odio = (puntuacion_odio / total_palabras_odio * 100) if total_palabras_odio > 0 else 0\n",
    "densidad_no_odio = (puntuacion_no_odio / total_palabras_no_odio * 100) if total_palabras_no_odio > 0 else 0\n",
    "\n",
    "print(f\"ODIO - Densidad de puntuación expresiva: {densidad_odio:.2f}%\")\n",
    "print(f\"NO ODIO - Densidad de puntuación expresiva: {densidad_no_odio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODIO - Palabras ofensivas: 140 (0.8717%)\n",
      "NO ODIO - Palabras ofensivas: 352 (0.1879%)\n"
     ]
    }
   ],
   "source": [
    "#Proporción de palabras ofensivas como un pequeño lexicón de insultos \n",
    "#Trabajo con lemas en minúsculas para obtener variaciones morfológicas\n",
    "lexico_ofensivo = {\n",
    "    \"idiota\", \"imbécil\", \"imbecil\", \"asqueroso\", \"asquerosa\",\n",
    "    \"mierda\", \"mierdas\", \"payaso\", \"payasa\", \"cerdo\", \"cerda\",\n",
    "    \"estúpido\", \"estupido\", \"estúpida\", \"tonto\", \"tonta\",\n",
    "    \"gilipollas\", \"subnormal\", \"basura\", \"rata\", \"escoria\"\n",
    "}\n",
    "\n",
    "ofensivas_odio = 0\n",
    "ofensivas_no_odio = 0\n",
    "total_palabras_odio = 0\n",
    "total_palabras_no_odio = 0\n",
    "\n",
    "# Recorro cada documento spaCy y miro los lemas de los tokens alfabéticos\n",
    "for i, doc_i in enumerate(doc):\n",
    "    for token in doc_i:\n",
    "        if token.is_alpha:\n",
    "            lema = token.lemma_.lower()\n",
    "            if data[\"ES_ODIO\"].iloc[i]:\n",
    "                total_palabras_odio += 1\n",
    "                if lema in lexico_ofensivo:\n",
    "                    ofensivas_odio += 1\n",
    "            else:\n",
    "                total_palabras_no_odio += 1\n",
    "                if lema in lexico_ofensivo:\n",
    "                    ofensivas_no_odio += 1\n",
    "\n",
    "prop_ofensivas_odio = (ofensivas_odio / total_palabras_odio * 100) if total_palabras_odio > 0 else 0\n",
    "prop_ofensivas_no_odio = (ofensivas_no_odio / total_palabras_no_odio * 100) if total_palabras_no_odio > 0 else 0\n",
    "\n",
    "print(f\"ODIO - Palabras ofensivas: {ofensivas_odio} ({prop_ofensivas_odio:.4f}%)\")\n",
    "print(f\"NO ODIO - Palabras ofensivas: {ofensivas_no_odio} ({prop_ofensivas_no_odio:.4f}%)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODIO - Palabras únicas: 4448 de 16061\n",
      "ODIO - Type-Token Ratio (TTR): 27.69%\n",
      "\n",
      "NO ODIO - Palabras únicas: 22935 de 187299\n",
      "NO ODIO - Type-Token Ratio (TTR): 12.25%\n"
     ]
    }
   ],
   "source": [
    "# Diversidad léxica (Type-Token Ratio, TTR)\n",
    "tokens_unicos_odio = set()\n",
    "tokens_unicos_no_odio = set()\n",
    "total_tokens_odio = 0\n",
    "total_tokens_no_odio = 0\n",
    "\n",
    "# Recorro todos los documentos y recojo las palabras alfabéticas en minúsculas, diferenciando odio y sin odio\n",
    "for i in range(len(doc)):\n",
    "    for token in doc[i]:\n",
    "        if token.is_alpha:\n",
    "            palabra_lower = token.text.lower()\n",
    "            \n",
    "            if data[\"ES_ODIO\"].iloc[i]:\n",
    "                total_tokens_odio += 1\n",
    "                tokens_unicos_odio.add(palabra_lower)\n",
    "            else:\n",
    "                total_tokens_no_odio += 1\n",
    "                tokens_unicos_no_odio.add(palabra_lower)\n",
    "\n",
    "ttr_odio = (len(tokens_unicos_odio) / total_tokens_odio * 100) if total_tokens_odio > 0 else 0\n",
    "ttr_no_odio = (len(tokens_unicos_no_odio) / total_tokens_no_odio * 100) if total_tokens_no_odio > 0 else 0\n",
    "\n",
    "print(f\"ODIO - Palabras únicas: {len(tokens_unicos_odio)} de {total_tokens_odio}\")\n",
    "print(f\"ODIO - Type-Token Ratio (TTR): {ttr_odio:.2f}%\")\n",
    "print(f\"\\nNO ODIO - Palabras únicas: {len(tokens_unicos_no_odio)} de {total_tokens_no_odio}\")\n",
    "print(f\"NO ODIO - Type-Token Ratio (TTR): {ttr_no_odio:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ODIO - Verbos: 1824 (11.36%)\n",
      "NO ODIO - Verbos: 23497 (12.55%)\n",
      "Verbos imperativos en ODIO: 31\n",
      "Verbos imperativos en NO ODIO: 414\n"
     ]
    }
   ],
   "source": [
    "# Proporción de verbos y conteo de verbos en modo imperativo\n",
    "verbos_odio = 0\n",
    "verbos_no_odio = 0\n",
    "total_palabras_odio = 0\n",
    "total_palabras_no_odio = 0\n",
    "\n",
    "# Cuento cuántos tokens son VERB y cuántas palabras alfabéticas hay por grupo\n",
    "for i in range(len(doc)):\n",
    "    for token in doc[i]:\n",
    "        if token.is_alpha:\n",
    "            if data[\"ES_ODIO\"].iloc[i]:\n",
    "                total_palabras_odio += 1\n",
    "                if token.pos_ == \"VERB\":\n",
    "                    verbos_odio += 1\n",
    "            else:\n",
    "                total_palabras_no_odio += 1\n",
    "                if token.pos_ == \"VERB\":\n",
    "                    verbos_no_odio += 1\n",
    "\n",
    "prop_verbos_odio = (verbos_odio / total_palabras_odio * 100) if total_palabras_odio > 0 else 0\n",
    "prop_verbos_no_odio = (verbos_no_odio / total_palabras_no_odio * 100) if total_palabras_no_odio > 0 else 0\n",
    "\n",
    "print(f\"ODIO - Verbos: {verbos_odio} ({prop_verbos_odio:.2f}%)\")\n",
    "print(f\"NO ODIO - Verbos: {verbos_no_odio} ({prop_verbos_no_odio:.2f}%)\")\n",
    "\n",
    "# Verbos en modo imperativo según la morfología de spaCy\n",
    "verbos_imp_odio = 0\n",
    "verbos_imp_no_odio = 0\n",
    "\n",
    "for i in range(len(doc)):\n",
    "    for token in doc[i]:\n",
    "        if token.pos_ == \"VERB\":\n",
    "            if \"Mood=Imp\" in token.morph:\n",
    "                if data[\"ES_ODIO\"].iloc[i]:\n",
    "                    verbos_imp_odio += 1\n",
    "                else:\n",
    "                    verbos_imp_no_odio += 1\n",
    "\n",
    "print(\"Verbos imperativos en ODIO:\", verbos_imp_odio)\n",
    "print(\"Verbos imperativos en NO ODIO:\", verbos_imp_no_odio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RESUMEN COMPARATIVO DE CARACTERÍSTICAS\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "Característica                                 ODIO    NO ODIO   Diferencia\n",
      "--------------------------------------------------------------------------------\n",
      "Promedio de palabras                          22.89      21.54        6.27%\n",
      "Promedio de oraciones                          1.76       1.78        0.81%\n",
      "% con entidades NER                           38.24      33.71       13.42%\n",
      "Densidad puntuación expresiva (%)              2.59       2.58        0.14%\n",
      "% Palabras ofensivas (lexicón simple)          0.87       0.19      363.82%\n",
      "Type-Token Ratio (%)                          27.69      12.25      126.17%\n",
      "% Verbos                                      11.36      12.55        9.47%\n",
      "\n",
      "--------------------------------------------------------------------------------\n",
      "CONCLUSIÓN:\n",
      "--------------------------------------------------------------------------------\n",
      "\n",
      "La característica con MAYOR PODER DISCRIMINATORIO es:\n",
      "- Type-Token Ratio (TTR) - Diversidad léxica\n",
      "\n",
      "- Los mensajes de odio tienden a mostrar una mayor diversidad léxica\n",
      "- Esta característica podría usarse efectivamente como entrada de un clasificador\n",
      "\n",
      "La característica de porcentaje de palabras ofensivas también resulta muy relevante:\n",
      "- Se basa en un lexicón explícito de insultos\n",
      "- Captura carga lingüística agresiva directamente relacionada con el discurso de odio\n",
      "\n",
      "Características con poder discriminatorio MODERADO:\n",
      "- Promedio de palabras por comentario\n",
      "- % de comentarios con entidades NER\n",
      "\n",
      "Características con poco o nulo poder discriminatorio:\n",
      "- Promedio de oraciones\n",
      "- Densidad de puntuación expresiva\n",
      "- % de verbos sobre el total de palabras\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Análisis comparativo de todas las características\n",
    "import numpy as np\n",
    "\n",
    "print(\"RESUMEN COMPARATIVO DE CARACTERÍSTICAS\")\n",
    "\n",
    "# Porcentaje de comentarios con NER por grupo\n",
    "porcentaje_ner = data.groupby(\"ES_ODIO\")[\"TIENE_NER\"].mean() * 100\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Diccionario con las características calculadas\n",
    "caracteristicas = {\n",
    "    \"Promedio de palabras\": (medias_palabras[True], medias_palabras[False]),\n",
    "    \"Promedio de oraciones\": (medias_oraciones[True], medias_oraciones[False]),\n",
    "    \"% con entidades NER\": (porcentaje_ner[True], porcentaje_ner[False]),\n",
    "    \"Densidad puntuación expresiva (%)\": (densidad_odio, densidad_no_odio),\n",
    "    \"% Palabras ofensivas (lexicón simple)\": (prop_ofensivas_odio, prop_ofensivas_no_odio),\n",
    "    \"Type-Token Ratio (%)\": (ttr_odio, ttr_no_odio),\n",
    "    \"% Verbos\": (prop_verbos_odio, prop_verbos_no_odio)\n",
    "}\n",
    "\n",
    "print(f\"\\n{'Característica':<40} {'ODIO':>10} {'NO ODIO':>10} {'Diferencia':>12}\")\n",
    "print(\"-\"*80)\n",
    "\n",
    "# Imprimo para cada característica los valores en cada grupo y la diferencia relativa\n",
    "for nombre, (odio, no_odio) in caracteristicas.items():\n",
    "    diferencia = abs(odio - no_odio)\n",
    "    diff_relativa = (diferencia / no_odio * 100) if no_odio != 0 else 0\n",
    "    print(f\"{nombre:<40} {odio:>10.2f} {no_odio:>10.2f} {diff_relativa:>11.2f}%\")\n",
    "\n",
    "print(\"\\n\" + \"-\"*80)\n",
    "print(\"CONCLUSIÓN:\")\n",
    "print(\"-\"*80)\n",
    "print(\"\"\"\n",
    "La característica con MAYOR PODER DISCRIMINATORIO es:\n",
    "- Type-Token Ratio (TTR) - Diversidad léxica\n",
    "\n",
    "- Los mensajes de odio tienden a mostrar una mayor diversidad léxica\n",
    "- Esta característica podría usarse efectivamente como entrada de un clasificador\n",
    "\n",
    "La característica de porcentaje de palabras ofensivas también resulta muy relevante:\n",
    "- Se basa en un lexicón explícito de insultos\n",
    "- Captura carga lingüística agresiva directamente relacionada con el discurso de odio\n",
    "\n",
    "Características con poder discriminatorio MODERADO:\n",
    "- Promedio de palabras por comentario\n",
    "- % de comentarios con entidades NER\n",
    "\n",
    "Características con poco o nulo poder discriminatorio:\n",
    "- Promedio de oraciones\n",
    "- Densidad de puntuación expresiva\n",
    "- % de verbos sobre el total de palabras\n",
    "\"\"\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.12 – unir-pln",
   "language": "python",
   "name": "unir-pln"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
